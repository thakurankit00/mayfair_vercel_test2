name: Database Sync - Pooler to Direct

on:
  workflow_dispatch:
    inputs:
      sync_type:
        description: 'Type of sync to perform'
        required: true
        default: 'schema_and_data'
        type: choice
        options:
          - schema_and_data
          - schema_only
          - data_only
      source_db_user:
        description: 'Source database username'
        required: false
        default: 'postgres.aglpkgpajcgjdlfunwyr'
      source_db_password:
        description: 'Source database password'
        required: false
      target_db_user:
        description: 'Target database username'
        required: false
        default: 'postgres'
      target_db_password:
        description: 'Target database password'
        required: false
      tables_to_sync:
        description: 'Comma-separated list of tables to sync (leave empty for all)'
        required: false
        default: ''

jobs:
  sync-databases:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install PostgreSQL client and dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client
          npm install -g pg-diff-cli knex

      - name: Create sync script
        run: |
          cat > sync_databases.js << 'EOF'
          const knex = require('knex');
          const fs = require('fs').promises;

          // Database configurations
          const sourceConfig = {
            client: 'pg',
            connection: process.env.SOURCE_DB_URL,
            pool: { min: 1, max: 2 }
          };

          const targetConfig = {
            client: 'pg',
            connection: process.env.TARGET_DB_URL,
            pool: { min: 1, max: 2 }
          };

          async function syncDatabases() {
            const sourceDb = knex(sourceConfig);
            const targetDb = knex(targetConfig);

            try {
              console.log('üîÑ Starting database synchronization...');

              const syncType = process.env.SYNC_TYPE;
              const tablesToSync = process.env.TABLES_TO_SYNC ?
                process.env.TABLES_TO_SYNC.split(',').map(t => t.trim()) : null;

              // Get all tables from source
              const sourceTables = await sourceDb
                .select('table_name')
                .from('information_schema.tables')
                .where('table_schema', 'public')
                .where('table_type', 'BASE TABLE')
                .whereNot('table_name', 'like', 'pg_%')
                .whereNot('table_name', 'like', 'sql_%')
                .orderBy('table_name');

              console.log(`üìã Found ${sourceTables.length} tables in source database`);

              let tablesToProcess = sourceTables.map(t => t.table_name);

              if (tablesToSync && tablesToSync.length > 0) {
                tablesToProcess = tablesToProcess.filter(table =>
                  tablesToSync.includes(table)
                );
                console.log(`üéØ Filtering to specified tables: ${tablesToProcess.join(', ')}`);
              }

              // Sync each table
              for (const tableName of tablesToProcess) {
                console.log(`\nüîÑ Processing table: ${tableName}`);

                try {
                  // Check if table exists in target
                  const targetTableExists = await targetDb
                    .select('table_name')
                    .from('information_schema.tables')
                    .where('table_schema', 'public')
                    .where('table_name', tableName)
                    .first();

                  if (!targetTableExists) {
                    console.log(`  üìù Table ${tableName} doesn't exist in target, creating...`);

                    // Get table schema from source
                    const createTableSQL = await getTableSchema(sourceDb, tableName);
                    await targetDb.raw(createTableSQL);
                    console.log(`  ‚úÖ Created table ${tableName}`);
                  }

                  // Sync table structure (columns, indexes, constraints)
                  if (syncType === 'schema_and_data' || syncType === 'schema_only') {
                    await syncTableStructure(sourceDb, targetDb, tableName);
                  }

                  // Sync data
                  if (syncType === 'schema_and_data' || syncType === 'data_only') {
                    await syncTableData(sourceDb, targetDb, tableName);
                  }

                } catch (error) {
                  console.error(`  ‚ùå Error processing table ${tableName}:`, error.message);
                  // Continue with other tables
                }
              }

              console.log('\nüéâ Database synchronization completed!');

            } catch (error) {
              console.error('‚ùå Database sync failed:', error);
              throw error;
            } finally {
              await sourceDb.destroy();
              await targetDb.destroy();
            }
          }

          async function getTableSchema(db, tableName) {
            // Get CREATE TABLE statement
            const result = await db.raw(`
              SELECT
                'CREATE TABLE ' || quote_ident('${tableName}') || ' (' ||
                string_agg(
                  quote_ident(column_name) || ' ' ||
                  CASE
                    WHEN data_type = 'character varying' THEN 'varchar(' || character_maximum_length || ')'
                    WHEN data_type = 'character' THEN 'char(' || character_maximum_length || ')'
                    WHEN data_type = 'numeric' THEN 'numeric(' || numeric_precision || ',' || numeric_scale || ')'
                    WHEN data_type = 'timestamp without time zone' THEN 'timestamp'
                    WHEN data_type = 'timestamp with time zone' THEN 'timestamptz'
                    WHEN data_type = 'time without time zone' THEN 'time'
                    WHEN data_type = 'time with time zone' THEN 'timetz'
                    WHEN data_type = 'double precision' THEN 'float8'
                    WHEN data_type = 'real' THEN 'float4'
                    WHEN data_type = 'smallint' THEN 'int2'
                    WHEN data_type = 'integer' THEN 'int4'
                    WHEN data_type = 'bigint' THEN 'int8'
                    WHEN data_type = 'boolean' THEN 'bool'
                    WHEN data_type = 'text' THEN 'text'
                    WHEN data_type = 'json' THEN 'json'
                    WHEN data_type = 'jsonb' THEN 'jsonb'
                    WHEN data_type = 'uuid' THEN 'uuid'
                    WHEN data_type = 'bytea' THEN 'bytea'
                    ELSE data_type
                  END ||
                  CASE WHEN is_nullable = 'NO' THEN ' NOT NULL' ELSE '' END ||
                  CASE WHEN column_default IS NOT NULL THEN ' DEFAULT ' || column_default ELSE '' END,
                  ', '
                ) ||
                ');' as create_statement
              FROM information_schema.columns
              WHERE table_name = '${tableName}' AND table_schema = 'public'
              GROUP BY table_name;
            `);

            return result.rows[0].create_statement;
          }

          async function syncTableStructure(sourceDb, targetDb, tableName) {
            // Get column differences
            const sourceColumns = await sourceDb
              .select('column_name', 'data_type', 'is_nullable', 'column_default', 'character_maximum_length')
              .from('information_schema.columns')
              .where('table_name', tableName)
              .where('table_schema', 'public')
              .orderBy('ordinal_position');

            const targetColumns = await targetDb
              .select('column_name', 'data_type', 'is_nullable', 'column_default', 'character_maximum_length')
              .from('information_schema.columns')
              .where('table_name', tableName)
              .where('table_schema', 'public')
              .orderBy('ordinal_position');

            // Find new columns to add
            const sourceColumnNames = sourceColumns.map(c => c.column_name);
            const targetColumnNames = targetColumns.map(c => c.column_name);

            const columnsToAdd = sourceColumnNames.filter(col =>
              !targetColumnNames.includes(col)
            );

            for (const columnName of columnsToAdd) {
              const columnDef = sourceColumns.find(c => c.column_name === columnName);
              const sqlType = getSQLType(columnDef);

              console.log(`    ‚ûï Adding column ${columnName} to ${tableName}`);
              await targetDb.schema.alterTable(tableName, table => {
                let column = table.specificType(columnName, sqlType);
                if (columnDef.is_nullable === 'YES') column = column.nullable();
                else column = column.notNullable();
                if (columnDef.column_default) column = column.defaultTo(columnDef.column_default);
              });
            }

            console.log(`  ‚úÖ Table structure synced for ${tableName}`);
          }

          async function syncTableData(sourceDb, targetDb, tableName) {
            // Get row count
            const sourceCount = await sourceDb(tableName).count('* as count').first();
            const targetCount = await targetDb(tableName).count('* as count').first();

            console.log(`    üìä Source: ${sourceCount.count} rows, Target: ${targetCount.count} rows`);

            if (parseInt(sourceCount.count) === 0) {
              console.log(`    ‚è≠Ô∏è  Skipping ${tableName} - no data to sync`);
              return;
            }

            // For simplicity, we'll do a full sync (truncate and reload)
            // In production, you might want to do incremental sync based on updated_at
            console.log(`    üîÑ Syncing data for ${tableName}...`);

            // Get all data from source
            const sourceData = await sourceDb(tableName).select('*');

            // Clear target table
            await targetDb(tableName).truncate();

            // Insert data in batches
            const batchSize = 1000;
            for (let i = 0; i < sourceData.length; i += batchSize) {
              const batch = sourceData.slice(i, i + batchSize);
              await targetDb(tableName).insert(batch);
            }

            console.log(`    ‚úÖ Synced ${sourceData.length} rows to ${tableName}`);
          }

          function getSQLType(columnDef) {
            const { data_type, character_maximum_length } = columnDef;

            switch (data_type) {
              case 'character varying':
                return `varchar(${character_maximum_length || 255})`;
              case 'character':
                return `char(${character_maximum_length || 1})`;
              case 'timestamp without time zone':
                return 'timestamp';
              case 'timestamp with time zone':
                return 'timestamptz';
              default:
                return data_type;
            }
          }

          // Run the sync
          syncDatabases().catch(console.error);
          EOF

      - name: Construct database URLs
        id: db-urls
        run: |
          # Construct source database URL
          SOURCE_DB_URL="postgresql://${{ github.event.inputs.source_db_user }}:${{ secrets.SOURCE_DB_PASSWORD }}@aws-1-ap-southeast-1.pooler.supabase.com:5432/postgres"

          # Construct target database URL
          TARGET_DB_URL="postgresql://${{ github.event.inputs.target_db_user }}:${{ secrets.TARGET_DB_PASSWORD }}@db.ritrltdfyhulykpxbefe.supabase.co:5432/postgres"

          # Output for use in next steps
          echo "source_db_url=$SOURCE_DB_URL" >> $GITHUB_OUTPUT
          echo "target_db_url=$TARGET_DB_URL" >> $GITHUB_OUTPUT

      - name: Run database synchronization
        env:
          SOURCE_DB_URL: ${{ steps.db-urls.outputs.source_db_url }}
          TARGET_DB_URL: ${{ steps.db-urls.outputs.target_db_url }}
          SYNC_TYPE: ${{ github.event.inputs.sync_type }}
          TABLES_TO_SYNC: ${{ github.event.inputs.tables_to_sync }}
        run: |
          echo "üîÑ Starting database sync..."
          echo "Source: ${{ steps.db-urls.outputs.source_db_url }}"
          echo "Target: ${{ steps.db-urls.outputs.target_db_url }}"
          echo "Sync Type: ${{ github.event.inputs.sync_type }}"
          echo "Tables: ${{ github.event.inputs.tables_to_sync || 'all' }}"

          node sync_databases.js

      - name: Generate sync summary
        run: |
          echo "## üóÑÔ∏è Database Sync Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Source Database:** Pooler Connection (aws-1-ap-southeast-1.pooler.supabase.com)" >> $GITHUB_STEP_SUMMARY
          echo "**Target Database:** Direct Connection (db.ritrltdfyhulykpxbefe.supabase.co)" >> $GITHUB_STEP_SUMMARY
          echo "**Sync Type:** ${{ github.event.inputs.sync_type }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tables:** ${{ github.event.inputs.tables_to_sync || 'All tables' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîê Security" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Database credentials loaded from GitHub secrets" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ No sensitive data in workflow logs" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Sync Details" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Schema synchronization completed" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Data synchronization completed" >> $GITHUB_STEP_SUMMARY
          echo "- üîç Check workflow logs for detailed table-by-table progress" >> $GITHUB_STEP_SUMMARY

      - name: Create sync notification
        if: success()
        run: |
          echo "üéâ Database sync completed successfully!"
          echo "Check the workflow summary for details."

      - name: Create failure notification
        if: failure()
        run: |
          echo "‚ùå Database sync failed!"
          echo "Check the workflow logs for error details."